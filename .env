# Ollama Configuration
OLLAMA_HOST=http://localhost:11434
OLLAMA_MODEL=codellama:13b-instruct

# Project Configuration
MAX_FILE_SIZE_MB=10
MAX_CONTEXT_LENGTH=4000
OUTPUT_DIR=./generated_configs

# Optional: GitHub token for private repos (if needed later)
# GITHUB_TOKEN=your_token_here